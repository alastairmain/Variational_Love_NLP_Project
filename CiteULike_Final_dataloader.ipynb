{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Dataset, BucketIterator, Field, TabularDataset, Iterator\n",
    "from torchtext.vocab import Vocab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condence(nparr):\n",
    "    uniq = np.unique(nparr)\n",
    "    name2idx = {o:i for i,o in enumerate(uniq)}\n",
    "    return np.array([name2idx[o] for o in nparr]), uniq\n",
    "\n",
    "## Read set\n",
    "data='data/citeulike/raw-data.csv'\n",
    "interactions = 'data/citeulike/user-info.csv'\n",
    "rawtext = pd.read_csv(data)\n",
    "interactions = pd.read_csv(interactions)\n",
    "interactions[\"user.id\"], uniq = condence(interactions[\"user.id\"].values)\n",
    "sizes = [0.7, 0.2]\n",
    "\n",
    "iteractions = np.random.shuffle(interactions.values) # Shuffle\n",
    "interactions[\"doc.id\"] = [rawtext.iloc[int(idx),1] for idx in interactions[\"doc.id\"]]\n",
    "\n",
    "n = len(interactions)\n",
    "train_size = int(sizes[0] * n)\n",
    "val_size = int(sizes[1] * n)\n",
    "test_size = n - train_size - val_size\n",
    "\n",
    "train = interactions[:train_size]\n",
    "val = interactions[train_size:train_size+val_size]\n",
    "test = interactions[train_size+val_size:]\n",
    "\n",
    "n = len(train)\n",
    "\n",
    "uniq_items = np.unique(rawtext[\"doc.id\"])[:-1]\n",
    "uniq_users = np.unique(train[\"user.id\"])[:-1]\n",
    "items = set((x[0],x[1]) for x in train[[\"user.id\",\"doc.id\"]].values)\n",
    "\n",
    "pairs = []\n",
    "i = 0\n",
    "while(i < n):\n",
    "    \n",
    "    item = np.random.choice(uniq_items, size = 1)[0]\n",
    "    user = np.random.choice(uniq_users, size = 1)[0]\n",
    "    if (user,item) not in items:\n",
    "        i += 1\n",
    "        pairs += [(user,item,0)]\n",
    "        items.add((user,item))\n",
    "\n",
    "interactionsNegatives = np.vstack((train, pairs))\n",
    "\n",
    "train = pd.DataFrame(data = interactionsNegatives,\n",
    "                                    columns = [\"user.id\",\"doc.id\", \"rating\"]\n",
    "                                    )\n",
    "\n",
    "\n",
    "train[\"doc.id\"].loc[n:] = [rawtext.iloc[int(idx),1] for idx in train[\"doc.id\"].loc[n:]]\n",
    "\n",
    "train = train.sample(frac=1) #shuffle panda style\n",
    "\n",
    "train.to_csv('data/citeulike/train.csv', header = False, index = False)\n",
    "val.to_csv('data/citeulike/val.csv', header = False, index = False)\n",
    "test.to_csv('data/citeulike/test.csv', header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip:  22%|██▏       | 190M/862M [07:38<34:14, 327kB/s]     "
     ]
    }
   ],
   "source": [
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "TEXT = Field(sequential=True, lower=True)\n",
    "LABEL = Field(sequential=False, use_vocab=False)\n",
    "ID = Field(sequential=False, use_vocab=False)\n",
    "\n",
    "train, val, test = TabularDataset.splits(\n",
    "        path='data/citeulike', train='train.csv',\n",
    "        validation='val.csv', test='test.csv', format='csv',\n",
    "        fields=[('ID', ID), ('Text', TEXT), ('Label', LABEL)])\n",
    "\n",
    "TEXT.build_vocab(train, vectors=\"glove.6B.100d\")\n",
    "LABEL.build_vocab(train)\n",
    "ID.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
