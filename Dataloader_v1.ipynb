{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from scipy.sparse import rand as sprand\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils import data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The grand dataset\n",
    "ratings = pd.read_csv('ratings_small.csv', usecols = ['userId','movieId','rating'])\n",
    "#ratings\n",
    "#ratings.movieId\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# Formatting the data \n",
    "\n",
    "class MovieLens(Dataset):\n",
    "  #'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self,csv_file,root_dir):\n",
    "        'Initialization'\n",
    "        self.movieLens = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        \n",
    "    def __len__(self):\n",
    "     #   'Denotes the total number of samples'\n",
    "        return len(self.movieLens)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "     #   'Generates one sample of data'\n",
    "        # Select sample\n",
    "        \n",
    "        movieId = self.movieLens.movieId.iloc[index]\n",
    "        userId =self.movieLens.userId[index]\n",
    "        rating = self.movieLens.rating[index]\n",
    "        #obs = {'movieId':movieId,'userId':userId,'rating':rating}\n",
    "        #obs = self.movieLens.drop('timestamp',axis=1)\n",
    "        #obs = obs.iloc[index,:].as_matrix()\n",
    "\n",
    "        return [movieId,userId,rating]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1029, 1, 3.0]\n",
      "100004\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "x = MovieLens(csv_file='ratings_small.csv',root_dir=None)\n",
    "print(x[1])\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_dataset = True\n",
    "train_split=0.7\n",
    "validation_split=0.2\n",
    "test_split=0.1\n",
    "random_seed= 42\n",
    "dataset_size = len(x)\n",
    "indices = list(range(dataset_size))\n",
    "\n",
    "               \n",
    "split_1 = int(np.floor(train_split * dataset_size))\n",
    "split_2 = split_1+int(np.floor(validation_split * dataset_size))\n",
    "split_3 = split_2+int(np.floor(test_split * dataset_size))\n",
    "split_2end=split_3-split_2\n",
    "\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices, test_indices = indices[:split_1], indices[split_1:-split_2end], indices[split_2:]\n",
    "\n",
    "#train_dataset, test_dataset, val_dataset = torch.utils.data.random_split(x, [train_size, test_size,val_size])\n",
    "train_dataset, test_dataset, val_dataset = x[train_indices], x[val_indices], x[test_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,batch_size = 4,shuffle=True)\n",
    "\n",
    "#print(train_dataloader)\n",
    "\n",
    "#for i_batch, sample_batched in enumerate(train_dataloader):\n",
    "#    print(i_batch)\n",
    "#    print(sample_batched)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset,batch_size = 4,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataloader = DataLoader(val_dataset,batch_size = 4,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671 8010\n"
     ]
    }
   ],
   "source": [
    "# instantiating model class\n",
    "num_users = len(ratings.userId[train_indices].unique())\n",
    "num_items = len(ratings.movieId[train_indices].unique())\n",
    "print(num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#users = torch.LongTensor(ratings.userId.values)\n",
    "#movies = torch.LongTensor(ratings.movieId.values)\n",
    "#ratings = torch.FloatTensor(ratings.rating.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.size>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF_bias(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=100):\n",
    "        super(MF_bias, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "        # init \n",
    "        self.user_emb.weight.data.uniform_(0,0.05)\n",
    "        self.item_emb.weight.data.uniform_(0,0.05)\n",
    "        self.user_bias.weight.data.uniform_(-0.01,0.01)\n",
    "        self.item_bias.weight.data.uniform_(-0.01,0.01)\n",
    "        \n",
    "    def forward(self,userId,movieId):\n",
    "        U = self.user_emb(userId)\n",
    "        V = self.item_emb(movieId)\n",
    "        b_u = self.user_bias(userId).squeeze()\n",
    "        b_v = self.item_bias(movieId).squeeze()\n",
    "        return (U*V).sum(1) +  b_userId  + b_movieId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MF_bias(num_users, num_items, emb_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movieId' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c43b1fdf611e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmovieId\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'movieId' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, epochs=10, lr=0.01, wd=0.0, unsqueeze=False):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters()) # get all parameters which need grad\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    model.train() # into training mode\n",
    "    for i in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for j, data in enumerate(train_loader):\n",
    "            users, items, ratings = data\n",
    "            users = Variable(users)\n",
    "            items = Variable(items)\n",
    "            ratings = Variable(ratings).float()\n",
    "            \n",
    "            users = users.cuda() # put on gpu\n",
    "            items = items.cuda()\n",
    "            ratings = ratings.cuda()            \n",
    "            if unsqueeze:\n",
    "                ratings = ratings.unsqueeze(1)\n",
    "            y_hat = model(users, items)\n",
    "            loss = F.mse_loss(y_hat, ratings)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.data[0]\n",
    "        print(\"training loss for epoch \",i+1, \": \", running_loss/j+1) # used to be loss.data[0]\n",
    "    test_loss(model, unsqueeze)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###NEDESTÃ…ENDE ER GAMMEL LORT ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user=ratings.userId\n",
    "user = user.values\n",
    "\n",
    "item = ratings.movieId\n",
    "item = item.values\n",
    "\n",
    "\n",
    "#ratings = torch.tensor(ratings.values)\n",
    "#ratings=ratings.toarray()\n",
    "print(user)\n",
    "print(item)\n",
    "n_users = len(user)\n",
    "n_items= len(item)\n",
    "\n",
    "\n",
    "ratings = ratings.pivot(index='userId', columns='movieId', values='rating')\n",
    "mat = ratings.values\n",
    "mat[np.isnan(mat)] = 0\n",
    "#mat=mat.astype(int)\n",
    "print(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        self.user_factors = torch.nn.Embedding(n_users, \n",
    "                                               n_factors,\n",
    "                                               sparse=True)\n",
    "        #print(self.user_factors)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, \n",
    "                                               n_factors,\n",
    "                                               sparse=True)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        return (self.user_factors(user) * self.item_factors(item)).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MatrixFactorization(n_users, n_items, n_factors=20)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), \n",
    "                            lr=1e-6) # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = mat.nonzero()\n",
    "print(rows)\n",
    "print(cols)\n",
    "p = np.random.permutation(len(rows))\n",
    "print(p)\n",
    "rows, cols = rows[p], cols[p]\n",
    "print(rows)\n",
    "print(cols)\n",
    "\n",
    "for row, col in zip(*(rows, cols)):\n",
    "    # Turn data into variables\n",
    "    rating = Variable(torch.FloatTensor([mat[row, col]]))\n",
    "    row = Variable(torch.LongTensor([np.long(row)]))\n",
    "    col = Variable(torch.LongTensor([np.long(col)]))\n",
    "    \n",
    "    # Predict and calculate loss\n",
    "    prediction = model(row, col)\n",
    "    loss = loss_func(prediction, rating)\n",
    "    \n",
    "    # Backpropagate\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(rating)\n",
    "    print(row)\n",
    "    print(col)\n",
    "    print(prediction)\n",
    "    print(loss)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
