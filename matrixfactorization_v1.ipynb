{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters in the model\n",
    "Matrix R: containing the ratings \n",
    "Matrix U: Containing the embeddings of the users\n",
    "Matrix M: Containing the embedding of the movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from scipy.sparse import rand as sprand\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils import data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The grand dataset\n",
    "ratings_dataset = pd.read_csv('ratings_small.csv', usecols = ['userId','movieId','rating'])\n",
    "\n",
    "#ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new indices\n",
    "\n",
    "def proc_col(col, train_col=None):\n",
    "    \"\"\"Encodes a pandas column with continous ids. \"\"\"\n",
    "    if train_col is not None:\n",
    "        uniq = train_col.unique()\n",
    "    else:\n",
    "        uniq = col.unique()\n",
    "    name2idx = {o:i for i,o in enumerate(uniq)}\n",
    "    return name2idx, np.array([name2idx.get(x, -1) for x in col]), len(uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(ratings_dataset, train=None):\n",
    "    \"\"\" Encodes rating data with continous user and movie ids. \n",
    "    If train is provided, encodes df with the same encoding as train.\n",
    "    \"\"\"\n",
    "    ratings_dataset = ratings_dataset.copy()\n",
    "    for col_name in [\"userId\", \"movieId\"]:\n",
    "        train_col = None\n",
    "        if train is not None:\n",
    "            train_col = train[col_name]\n",
    "        _,col,_ = proc_col(ratings_dataset[col_name], train_col)\n",
    "        ratings_dataset[col_name] = col\n",
    "        ratings_dataset = ratings_dataset[ratings_dataset[col_name] >= 0]\n",
    "    return ratings_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_dataset_e=encode_data(ratings_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70002\n",
      "20001\n",
      "10001\n"
     ]
    }
   ],
   "source": [
    "# split train and validation before encoding\n",
    "trn_len = ratings_dataset_e.shape[0]- int(0.3*ratings_dataset_e.shape[0])\n",
    "val_len = int(0.2*ratings_dataset_e.shape[0])\n",
    "test_len = int(0.1*ratings_dataset_e.shape[0])\n",
    "\n",
    "train = ratings_dataset_e[:trn_len-1].copy()\n",
    "val = ratings_dataset_e[trn_len:-test_len].copy()\n",
    "test = ratings_dataset_e[trn_len:-val_len].copy()\n",
    "\n",
    "print(len(train))\n",
    "print(len(val))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0]+ val.shape[0]+ test.shape[0] == ratings_dataset_e.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# Formatting the data \n",
    "\n",
    "class MovieLens(Dataset):\n",
    "  #'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self,users,movies,ratings):\n",
    "        'Initialization'\n",
    "        self.movies=movies\n",
    "        self.users=users\n",
    "        self.ratings=ratings\n",
    "        \n",
    "    def __len__(self):\n",
    "     #   'Denotes the total number of samples'\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "     #   'Generates one sample of data'\n",
    "        # Select sample\n",
    "        \n",
    "        U = self.users[index]\n",
    "        V =self.movies[index]\n",
    "        y = self.ratings[index]\n",
    "        #obs = {'movieId':movieId,'userId':userId,'rating':rating}\n",
    "        #obs = self.movieLens.drop('timestamp',axis=1)\n",
    "        #obs = obs.iloc[index,:].as_matrix()\n",
    "\n",
    "        return [U,V,y]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = torch.LongTensor(train.userId.values)\n",
    "movies = torch.LongTensor(train.movieId.values)\n",
    "ratings = torch.FloatTensor(train.rating.values)\n",
    "\n",
    "train_dataset = MovieLens(users, movies, ratings)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valid loader\n",
    "users_val = torch.LongTensor(val.userId.values)\n",
    "movies_val = torch.LongTensor(val.movieId.values)\n",
    "ratings_val = torch.FloatTensor(val.rating.values)\n",
    "\n",
    "val_dataset = MovieLens(users_val, movies_val, ratings_val)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# test loader\n",
    "users_test = torch.LongTensor(test.userId.values)\n",
    "movies_test = torch.LongTensor(test.movieId.values)\n",
    "ratings_test = torch.FloatTensor(test.rating.values)\n",
    "\n",
    "test_dataset = MovieLens(users_test, movies_test, ratings_test)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 474,  361,  262,  261,  477,   22,  212,  312,  238,  477,\n",
       "          239,  414,  293,  377,  352,  252,  232,   93,  100,  264,\n",
       "           96,   22,  345,  200,   55,  230,  344,   22,  460,   22,\n",
       "          379,  459,  267,  222,  262,  429,  392,   22,  171,  284,\n",
       "           14,  101,  104,  387,  185,  452,  456,  109,  262,  284,\n",
       "           22,  293,   68,  406,  305,  379,  357,  368,  148,  407,\n",
       "          231,  104,  211,  389,  445,  291,  460,  406,  119,  211,\n",
       "          400,  456,  219,   25,  456,  168,  479,  211,  211,  104,\n",
       "          432,   67,  387,  188,   14,  151,  288,  406,   97,  346,\n",
       "           55,  451,  406,  123,  399,  175,  213,  310,  242,  243]),\n",
       " tensor([  553,   402,   110,  5819,  1550,   124,   282,  1162,  2592,\n",
       "           387,  5293,   148,    19,  1652,   323,  1079,   714,  3181,\n",
       "          2251,   160,  3579,   776,    18,   126,   111,    49,   186,\n",
       "          2428,  2216,   900,  1690,   696,   496,  3596,   489,  2471,\n",
       "          5762,   584,  2539,   220,   652,  4395,   736,  6836,  5032,\n",
       "           647,  1253,    36,   324,   150,  2433,    52,  3603,  1262,\n",
       "           878,  3274,  4477,    36,  1888,   179,   261,    58,  1525,\n",
       "           428,  1826,   947,  1161,  4561,   963,   872,   211,    61,\n",
       "          5477,   564,  6838,  3854,  1330,  3020,  5311,  1260,   327,\n",
       "           367,  2366,  2638,   418,   513,  2946,  2499,  1343,   129,\n",
       "          1850,  2153,  4378,   188,    67,  4980,   174,   531,   985,\n",
       "          1386]),\n",
       " tensor([ 5.0000,  4.5000,  4.0000,  1.5000,  3.5000,  3.5000,  3.0000,\n",
       "          2.0000,  3.0000,  3.5000,  4.0000,  3.0000,  3.0000,  3.5000,\n",
       "          3.0000,  2.0000,  3.0000,  3.5000,  2.0000,  5.0000,  1.0000,\n",
       "          3.5000,  5.0000,  4.0000,  4.0000,  5.0000,  5.0000,  3.0000,\n",
       "          2.5000,  3.5000,  3.0000,  4.5000,  4.0000,  5.0000,  1.5000,\n",
       "          4.0000,  4.5000,  4.0000,  5.0000,  4.0000,  4.0000,  4.0000,\n",
       "          3.5000,  3.0000,  4.5000,  2.0000,  2.0000,  4.0000,  3.5000,\n",
       "          3.0000,  3.5000,  3.5000,  5.0000,  5.0000,  3.0000,  4.0000,\n",
       "          1.0000,  3.0000,  5.0000,  5.0000,  5.0000,  4.0000,  3.0000,\n",
       "          4.0000,  4.0000,  2.5000,  1.0000,  5.0000,  4.0000,  2.5000,\n",
       "          5.0000,  2.5000,  2.0000,  3.5000,  3.5000,  4.0000,  4.0000,\n",
       "          2.5000,  2.5000,  4.0000,  5.0000,  3.0000,  4.0000,  1.0000,\n",
       "          4.5000,  3.5000,  4.5000,  5.0000,  4.0000,  4.5000,  4.0000,\n",
       "          4.0000,  4.0000,  3.5000,  3.0000,  3.5000,  4.0000,  3.0000,\n",
       "          3.5000,  4.0000])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing one batch from the train dataloader\n",
    "t1= iter(train_loader)\n",
    "next(t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_user, num_movie, emb_size=100):\n",
    "        super(Model, self).__init__()\n",
    "        self.userEmb = nn.Embedding(num_user, emb_size)\n",
    "        self.movieEmb = nn.Embedding(num_movie, emb_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, u, v):\n",
    "        U = self.userEmb(u)\n",
    "        V = self.movieEmb(v)\n",
    "        return (U*V).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_user = len(train.userId.unique()) \n",
    "num_movie = len(train.movieId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x119413af0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_size = 100\n",
    "model=Model(num_user,num_movie,emb_size)\n",
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 9.2559e-01,  1.3112e-01, -2.0608e-01,  ...,  1.3571e+00,\n",
       "           5.4470e-01,  2.0903e-01],\n",
       "         [-2.7771e-01, -1.4926e+00, -9.5142e-01,  ...,  2.2129e+00,\n",
       "           2.5391e+00, -3.4938e-01],\n",
       "         [-3.9371e-01,  1.7334e+00, -1.5802e+00,  ..., -9.0567e-01,\n",
       "          -2.9499e-01, -1.9444e+00],\n",
       "         ...,\n",
       "         [ 1.4395e+00,  2.7408e-01, -1.6173e-01,  ..., -1.3254e-01,\n",
       "           1.1755e+00, -3.3505e-02],\n",
       "         [ 5.5287e-01,  5.8283e-01, -5.9406e-02,  ...,  1.1176e-01,\n",
       "          -1.1838e+00, -1.1384e+00],\n",
       "         [-4.6642e-01, -1.1818e-01,  2.2425e-02,  ...,  4.5563e-01,\n",
       "           1.5919e+00, -6.2725e-01]]), Parameter containing:\n",
       " tensor([[ 1.3931e+00,  5.0361e-01,  8.7920e-01,  ...,  2.4264e-01,\n",
       "           1.3643e-01,  6.5278e-01],\n",
       "         [ 1.1166e+00,  2.2333e+00,  4.1351e-01,  ...,  2.2008e-01,\n",
       "           5.0890e-02,  4.3604e-01],\n",
       "         [-5.0180e-01,  7.9520e-01,  1.1026e+00,  ...,  2.1945e-01,\n",
       "           3.7534e-01, -4.2002e-01],\n",
       "         ...,\n",
       "         [-1.9411e+00, -3.1422e-01,  1.6314e-01,  ...,  1.4084e+00,\n",
       "          -8.2431e-01, -1.5885e+00],\n",
       "         [-6.5783e-02, -5.1744e-01,  8.8404e-01,  ..., -7.9991e-01,\n",
       "          -2.7787e-01, -1.4028e+00],\n",
       "         [ 5.1821e-01, -5.3907e-02, -1.5381e+00,  ...,  7.2045e-01,\n",
       "          -3.9564e-02,  1.0664e+00]])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for p in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loss(model):\n",
    "    model.eval() # go to evaluation mode\n",
    "    \n",
    "    running_loss = 0.\n",
    "    for j, data in enumerate(val_loader):\n",
    "        users, items, ratings = data\n",
    "        users = Variable(users)\n",
    "        items = Variable(items)\n",
    "        ratings = Variable(ratings).float()\n",
    "            \n",
    "        \n",
    "        y_hat = model(users, items)\n",
    "        loss_now = F.mse_loss(y_hat, ratings)\n",
    "        running_loss+= loss_now.data[0]\n",
    "        \n",
    "        print(running_loss)\n",
    "    print(\"validation loss\", \": \", running_loss/len(val_loader)) # j means this many iterations till end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, epochs=2, lr=0.01, wd=0.0):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters()) # get all parameters which need grad\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    model.train() # into training mode\n",
    "    for i in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for j, data in enumerate(train_loader):\n",
    "            users, items, ratings = data\n",
    "            users = Variable(users)\n",
    "            items = Variable(items)\n",
    "            ratings = Variable(ratings).float()\n",
    "      \n",
    "\n",
    "            y_hat = model(users, items)\n",
    "            loss = F.mse_loss(y_hat, ratings)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.data[0]\n",
    "        print(\"training loss for epoch \",i+1, \": \", running_loss/j+1) # used to be loss.data[0]\n",
    "    test_loss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss for epoch  1 :  tensor(2.8671)\n",
      "training loss for epoch  2 :  tensor(2.7537)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index out of range at /Users/soumith/minicondabuild3/conda-bld/pytorch_1524590658547/work/aten/src/TH/generic/THTensorMath.c:343",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-3a3ea3c10dde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_epocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-71c191163719>\u001b[0m in \u001b[0;36mtrain_epocs\u001b[0;34m(model, epochs, lr, wd)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training loss for epoch \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\": \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# used to be loss.data[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-0a3eecff7f05>\u001b[0m in \u001b[0;36mtest_loss\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss_now\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mrunning_loss\u001b[0m\u001b[0;34m+=\u001b[0m \u001b[0mloss_now\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-81d5c99170cf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, u, v)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muserEmb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovieEmb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    106\u001b[0m         return F.embedding(\n\u001b[1;32m    107\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1074\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index out of range at /Users/soumith/minicondabuild3/conda-bld/pytorch_1524590658547/work/aten/src/TH/generic/THTensorMath.c:343"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=2, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
